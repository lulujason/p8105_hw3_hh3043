---
title: "p8105_hw3_hh3043"
output: github_document
---
```{r}
library(tidyverse)
library(dplyr)
library(p8105.datasets)
library(patchwork)
library(tidyr)
```
There are 1384617 observations and 15 variables. Each row is the information about the order. There are variables named order_id and product_id which let us figure out the id number of order and product.There is also variable describing name of the product(e.g. Spring Water).Variables including department_id and department offers information about the department(e.g. dairy eggs) of the product.

```{r}
data("instacart")
instacart =
  instacart|>
  as_tibble()
instacart|>
  count(aisle) |>
  arrange(desc(n))

```
There are 134 aisles and the aisle fresh vegetables is ordered the most.

```{r}
instacart |>
  count(aisle) |>
  arrange(desc(n))|>
  filter(n > 10000)|>
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() +
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 50, hjust = 1))


  

```

```{r}
instacart |>
  filter((aisle == "baking ingredients") | (aisle == "dog food care")| (aisle == "packaged vegetables fruits")) |>
  group_by(aisle) |>
  count(product_name) |>
  mutate(rank = min_rank(desc(n))) |>
  filter(rank < 4) |>
  arrange(desc(n)) |>
  knitr::kable()
```

```{r}
instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_hour = mean(order_hour_of_day)) |>
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour) |>
  knitr::kable()
```

Problem 2

```{r}

data("brfss_smart2010")

brfss_smart = 
  brfss_smart2010 |>
  as_tibble()|>
  janitor::clean_names()|>
  rename(state = locationabbr)|>
  filter(topic == 'Overall Health')|>
  filter(response %in% c('Excellent','Poor'))|>
  arrange(desc(response))
```

```{r}
brfss_smart |>
  filter(year == 2002)|>
  group_by(state)|>
  summarize(n_locations = n_distinct(locationdesc))|>
  arrange(desc(n_locations))
brfss_smart |>
  filter(year == 2010)|>
  group_by(state)|>
  summarize(n_locations = n_distinct(locationdesc))|>
  arrange(desc(n_locations))

```
In 2002, PA,MA,NJ,CT,FL,NC are states were observed at 7 or more locations.
iN2010, FL,NJ,TX,CA,MD,NC,NE,WA,MA,NY,OH,CO,PA,SC are states were observed at 7 or more locations.

```{r}
brfss_smart |>
  filter(response == 'Excellent')|>
  group_by(state,year) |>
  summarize(mean_data = mean(data_value))|>
  ggplot(aes(x = year, y = mean_data, color = state)) + 
    geom_point() + geom_line() +
    theme(legend.position = "bottom")
```


```{r}
year2006_df = 
  brfss_smart |>
  filter((year == 2006) & (state == 'NY')) |>
  group_by(locationdesc)|>
  ggplot(aes(x = response, y = data_value)) + 
  geom_boxplot()+
  ggtitle('year2006')
 
year2010_df = 
  brfss_smart |>
  filter((year == 2010) & (state == 'NY')) |>
  group_by(locationdesc)|>
  ggplot(aes(x = response, y = data_value)) + 
  geom_boxplot()+
  ggtitle('year2010')

(year2010_df/year2006_df)

```


problem 3

clean and tidy accel and covar datasets,and then merge.
```{r}
accel = 
  read_csv(
    '.\\nhanes_accel.csv')|> 
  janitor::clean_names()|>
  pivot_longer(
    min1 : min1440,


    names_to = "min",
    names_prefix = "min",
    values_to = "mims"

  )


covar = 
  read_csv(
    '.\\nhanes_covar.csv',skip = 4
  )|>
  janitor::clean_names()|>
  drop_na()|>
  filter(age>=21)
  mutate(
      sex = recode(
        sex,
        "1" = "male", 
        "2" = "female"),
      education = recode(
        education, 
        "1" = "Less than high school",
        "2" = "High school equivalent",
        "3" = "More than high school")
      ) 
  
nhanes = inner_join(accel,covar)
  


```


```{r}

```



